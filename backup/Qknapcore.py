import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from amplify import FixstarsClient
from src.vrpfactory import vrpfactory
from src.knap_divpro import knap_dippro
from TSP import TSP

import time
import json
from datetime import timedelta, datetime
import numpy as np


class Core:
    def __init__(self):
        """Fixstars Amplifyã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¨­å®š"""
        self.client = FixstarsClient()
       
        self.client.token = "AE/Y0TY3dM834BNw0YGdHlkIg8oLsCvAsXB"
        print("ğŸ”‘ FixstarsClient initialized.")

    def to_native(o):
        """NumPyç³»ã‚’Pythonã®ãƒ—ãƒªãƒŸãƒ†ã‚£ãƒ–å‹ã«æ­£è¦åŒ–"""
        if isinstance(o, np.ndarray):
            return o.tolist()
        if isinstance(o, (np.integer,)):
            return int(o)
        if isinstance(o, (np.floating,)):
            return float(o)
        return o
    
    
    def main(self):
        import argparse
        parser = argparse.ArgumentParser(
            description="Iterative QA-based CVRP optimizer with detailed timing logs"
        )
        parser.add_argument("-j",   help="Path to before_data.json",             type=str, required=True)
        parser.add_argument("-sp",  help="Base output directory (e.g. ./out)",   type=str, required=True)
        parser.add_argument("--t",  help="Annealing time (ms)",                  type=int, default=3000)
        parser.add_argument("-nt",  help="QA solves per swap (num_solve)",       type=int, default=3)
        parser.add_argument("--p",  help="QA parameter p",                       type=float, default=1.0)
        parser.add_argument("--q",  help="QA parameter q",                       type=float, default=1.0)
        parser.add_argument("--max_iter", help="Max iterations (safety cap)",    type=int, default=50)
        parser.add_argument("--eps", help="Stop if improvement < eps",           type=float, default=1e-3)
        args = parser.parse_args()

        # === å‡ºåŠ›ãƒ«ãƒ¼ãƒˆ ===
        instance_name = os.path.splitext(os.path.basename(args.j))[0]
        timestamp     = datetime.now().strftime("%Y%m%d_%H%M%S")
        save_dir      = os.path.join(args.sp, timestamp, instance_name)
        os.makedirs(save_dir, exist_ok=True)

        print(f"\nğŸš€ å®Ÿé¨“é–‹å§‹: {instance_name}")
        print(f"ğŸ“‚ å‡ºåŠ›å…ˆ: {save_dir}")

        # === before_data.json èª­ã¿è¾¼ã¿ ===
        VRPfactory = vrpfactory()
        (
            cluster_nums, grax, gray, gra_distances,
            x, y, distances, demands, capacity,
            clusters, clusters_coordx, clusters_coordy, cluster_demands,
            gra_clusters_coordx, gra_clusters_coordy, depo_x, depo_y
        ) = VRPfactory.get_gluster_gravity_info(args.j)

        # å›ºå®šè¨­å®š
        nvehicle = 1
        depo_x, depo_y = depo_x[0], depo_y[0]
        self.client.parameters.timeout = timedelta(milliseconds=args.t)

        # === åˆæœŸã‚¯ãƒ©ã‚¹ã‚¿é †åºï¼ˆé‡å¿ƒTSPã§æ±ºå®šï¼‰ ===
        tsp_over_clusters = TSP(
            self.client, gra_distances, demands, capacity,
            nvehicle, args.nt, cluster_nums, save_dir, grax, gray, args.j
        )
        gra_result = tsp_over_clusters.des_TSP(args.p, args.q)
        perms = gra_result["route"][1:]  # depot(0)ã‚’é™¤ã
        print(f"ğŸ§­ Initial cluster order: {perms}")

        prev_total_distance = None
        iteration = 0

        while True:
            iteration += 1
            print(f"\n===== Iteration {iteration} =====")

            # 1) ã‚¯ãƒ©ã‚¹ã‚¿é–“å†é…ç½®ï¼ˆQAï¼‰â€” è©³ç´°è¨ˆæ¸¬ãƒ­ã‚°
            swap_time_log = []

            for idx, current_cluster_index in enumerate(perms):
                next_cluster_index = perms[(idx + 1) % len(perms)]

                # è¨ˆæ¸¬é–‹å§‹ï¼šã‚¯ãƒ©ã‚¹ã‚¿ãƒšã‚¢ç¢ºå®šç›´å¾Œ
                t_block_start = time.perf_counter()

                # ç¾åœ¨ã¨æ¬¡ã®ã‚¯ãƒ©ã‚¹ã‚¿æƒ…å ±ã‚’å–ã‚Šå‡ºã—
                current_x, current_y = x[current_cluster_index], y[current_cluster_index]
                current_demands      = demands[current_cluster_index]
                current_grax, current_gray = grax[current_cluster_index], gray[current_cluster_index]

                next_x, next_y       = x[next_cluster_index], y[next_cluster_index]
                next_demands         = demands[next_cluster_index]
                next_grax, next_gray = grax[next_cluster_index], gray[next_cluster_index]

                # æ¬¡ã‚¯ãƒ©ã‚¹ã‚¿ã®æ®‹ç©è¼‰é‡
                restcapacity = float(capacity - sum(next_demands))

                # 2ã¤ã®QAå…¥åŠ›è·é›¢è¡Œåˆ—
                distances_from_mycluster  = vrpfactory.make_distances(current_x, current_y, current_grax, current_gray)
                distances_from_nextcluster = vrpfactory.make_distances(current_x, current_y, next_grax, next_gray)

                # QA å®Ÿè¡Œï¼ˆå†…éƒ¨ã§ total_time / execution_time / response_time / route / total_distances ã‚’è¿”ã™æƒ³å®šï¼‰
                proccesor = knap_dippro(
                    self.client,
                    distances_from_mycluster,
                    distances_from_nextcluster,
                    current_demands,
                    restcapacity,
                    args.nt,
                    current_x,   # éƒ½å¸‚IDãƒªã‚¹ãƒˆç›¸å½“ï¼ˆã‚ãªãŸã®å®Ÿè£…ã«åˆã‚ã›ã¦ï¼‰
                    args.j
                )
                # ...ï¼ˆãƒ«ãƒ¼ãƒ—å†…ï¼šrecordä½œæˆã®ç›´å‰ã‚ãŸã‚Šã‚’ä¿®æ­£ï¼‰
            # QA å®Ÿè¡Œ
            pro_result = proccesor.QA_processors()

            # moved_indices ã‚’å–ã‚Šå‡ºã—ã¦ Python ã® list[int] ã«æ­£è¦åŒ–
            moved_raw = pro_result.get("route", [])
            if isinstance(moved_raw, np.ndarray):
                moved_indices = moved_raw.tolist()
            else:
                moved_indices = list(moved_raw) if not isinstance(moved_raw, list) else moved_raw

            # è¦ç´ ã‚’ã§ãã‚‹ã ã‘ int åŒ–ï¼ˆå¤±æ•—ã—ãŸã‚‰ãã®ã¾ã¾ï¼‰
            try:
                moved_indices = [int(x) for x in moved_indices]
            except Exception:
                # ä¾‹ãˆã° [0. 0. 0.] ã®ã‚ˆã†ãª float ãªã‚‰ int ã«è½ã¡ã‚‹ã¯ãšã ãŒã€
                # ä½•ã‹æ··åœ¨ã—ã¦ã„ãŸã‚‰ to_native ã§æœ€ä½é™ã®ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã¯ä¿è¨¼
                moved_indices = [to_native(x) for x in moved_indices]

            # è¨ˆæ¸¬
            t_block_end = time.perf_counter()
            block_ms = float((t_block_end - t_block_start) * 1000.0)

            qa_total_time = pro_result.get("total_time", 0.0)
            qa_ms = float(qa_total_time) * 1000.0  # total_time ãŒç§’æƒ³å®šã€‚ãƒŸãƒªç§’ãªã‚‰ã“ã“ã¯ãã®ã¾ã¾ float(qa_total_time)

            move_ms = max(block_ms - qa_ms, 0.0)

            record = {
                "iteration":     int(iteration),
                "swap_index":    int(idx),
                "from_cluster":  int(current_cluster_index),
                "to_cluster":    int(next_cluster_index),
                "qa_ms":         float(qa_ms),
                "move_ms":       float(move_ms),
                "block_ms":      float(block_ms),
                "moved_indices": moved_indices
            }
            swap_time_log.append(record)

            print(f"[swap {idx}] QA={qa_ms:.2f}ms | move={move_ms:.2f}ms | total={block_ms:.2f}ms | moved={moved_indices}")


            # ã‚¹ãƒ¯ãƒƒãƒ—æ™‚é–“ãƒ­ã‚°JSONä¿å­˜ï¼ˆé›†è¨ˆãªã—ãƒ»ç”Ÿé…åˆ—ï¼‰
            swap_log_path = os.path.join(save_dir, f"iteration_{iteration}_swap_timings.json")
            with open(swap_log_path, "w") as f:
                json.dump(swap_time_log, f, indent=2)
            print(f"ğŸ•’ ã‚¹ãƒ¯ãƒƒãƒ—è©³ç´°ã‚’ä¿å­˜: {swap_log_path}")

            # 2) å„ã‚¯ãƒ©ã‚¹ã‚¿å†…ã®TSPã‚’è§£ãç›´ã™
            total_distance = 0.0
            tsp_routes = []
            for cluster_id in range(len(clusters)):
                # å„ã‚¯ãƒ©ã‚¹ã‚¿ã®åº§æ¨™ï¼éœ€è¦ã‚’ãƒ‡ãƒè¾¼ã¿ã§æ•´å½¢
                coordx = [depo_x] + clusters_coordx[cluster_id]
                coordy = [depo_y] + clusters_coordy[cluster_id]
                cluster_demand = [0] + cluster_demands[cluster_id]
                city_list      = [0] + clusters[cluster_id]

                cluster_distance = vrpfactory.make_cluster_distance_matrix(coordx, coordy)

                tsp_solver = TSP(
                    self.client,
                    cluster_distance,
                    cluster_demand,
                    capacity,
                    1,               # 1è»Šä¸¡ï¼ˆã‚¯ãƒ©ã‚¹å†…TSPï¼‰
                    args.nt,
                    city_list,
                    save_dir,
                    coordx,
                    coordy,
                    args.j
                )
                result = tsp_solver.solve_TSP(args.p, args.q)
                tsp_routes.append({
                    "cluster_id":      cluster_id,
                    "route":           result["route"],
                    "total_time":      result.get("total_time", None),
                    "execution_time":  result.get("execution_time", None),
                    "response_time":   result.get("response_time", None),
                    "total_distance":  result.get("total_distances", None)
                })
                total_distance += float(result.get("total_distances", 0.0))

            print(f"ğŸ“ Total distance after iteration {iteration}: {total_distance:.6f}")

            # 3) æ”¹å–„åˆ¤å®šï¼ˆä¿å­˜ã¯æ¯å›è¡Œã†ï¼‰
            # TSPçµæœã‚’ä¿å­˜
            iteration_path = os.path.join(save_dir, f"iteration_{iteration}.json")
            with open(iteration_path, "w") as f:
                json.dump(tsp_routes, f, indent=2)
            print(f"ğŸ’¾ ä¿å­˜: {iteration_path}")

            # åæŸåˆ¤å®š
            if prev_total_distance is not None:
                improvement = prev_total_distance - total_distance
                print(f"ğŸŸ¢ Improvement: {improvement:.6f}")
                if abs(improvement) < args.eps:
                    print("âš ï¸ æ”¹å–„ãŒåœæ­¢ã—ãŸãŸã‚çµ‚äº†ã€‚")
                    break

            prev_total_distance = total_distance

            if iteration >= args.max_iter:
                print("âš ï¸ æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã«é”ã—ãŸãŸã‚åœæ­¢ã€‚")
                break

        print("\nâœ… Optimization completed.")
        print(f"ğŸ“‚ Results saved in: {save_dir}")


if __name__ == "__main__":
    core = Core()
    core.main()
